# worker_app.py

# === åŸºæœ¬è¨­å®š ===
from settings import *

import os
import json
import logging
import tempfile
import datetime
from celery import Celery, chord, group
from celery.exceptions import SoftTimeLimitExceeded
from googleapiclient.errors import HttpError
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.credentials import Credentials
import pymysql
from linebot.v3.messaging import (
    ReplyMessageRequest,
    Configuration,
    ApiClient,
    MessagingApi,
    TextMessage,
    ButtonsTemplate,
    TemplateMessage,
    MessageAction,
    MessagingApiBlob,
    ShowLoadingAnimationRequest,
    URIAction,
    CarouselColumn,
    CarouselTemplate
)
from dbutils.pooled_db import PooledDB  # æ”¹ç”¨ PooledDB
import time


configuration = Configuration(
    access_token=CHANNEL_ACCESS_TOKEN,
)

celery = Celery('worker_app', broker=CELERY_BROKER_URL, backend=CELERY_BACKEND_URL)

# è¨­å®šæ™‚å€
celery.conf.timezone = 'UTC'

# è¨­å®šå®šæœŸä»»å‹™
celery.conf.beat_schedule = {
    'clean-old-upload-logs-every-day': {
        'task': 'worker_app.clean_old_upload_logs',
        'schedule': 86400.0,  # æ¯86400ç§’ï¼ˆå³æ¯å¤©åŸ·è¡Œä¸€æ¬¡ï¼‰
        'args': (7,)  # å‚³éåƒæ•¸ï¼Œé€™è£¡æ˜¯ä¿ç•™7å¤©çš„æ—¥èªŒ
    },
    'clean-tmp-logs-every-10-minutes': {
        'task': 'worker_app.clean_tmp_logs',
        'schedule': 600.0,  # æ¯600ç§’ï¼ˆå³10åˆ†é˜åŸ·è¡Œä¸€æ¬¡ï¼‰
        'args': (30,)  # å‚³éåƒæ•¸ï¼Œé€™è£¡æ˜¯ä¿ç•™30åˆ†é˜çš„æ—¥èªŒ
    },
}

class UserCredentialsError(Exception):
    """ä½¿ç”¨è€…æ†‘è­‰éŒ¯èª¤"""
    pass

# æ—¥èªŒè¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# å»ºç«‹è³‡æ–™åº«é€£ç·šæ± 
db_pool = PooledDB(
    creator=pymysql,
    maxconnections=6,      # é€£ç·šæ± å…è¨±çš„æœ€å¤§é€£ç·šæ•¸
    mincached=2,           # åˆå§‹åŒ–æ™‚ï¼Œé€£ç·šæ± ä¸­è‡³å°‘å»ºç«‹çš„ç©ºé–’é€£ç·šæ•¸é‡
    maxcached=4,           # é€£ç·šæ± ä¸­å…è¨±çš„æœ€å¤§ç©ºé–’é€£ç·šæ•¸é‡
    maxshared=2,           # å…±äº«é€£ç·šæ•¸é‡
    blocking=True,         # é€£ç·šæ± æ»¿æ™‚æ˜¯å¦ç­‰å¾…
    host=DATABASE["HOST"],
    user=DATABASE["USER"],
    password=DATABASE["PASSWORD"],
    database=DATABASE["DB"],
    charset='utf8mb4',
    autocommit=False,
)
def reply_message(reply_token, messages):
    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)
        line_bot_api.reply_message_with_http_info(
            ReplyMessageRequest(
                reply_token=reply_token,
                messages=messages
            )
        )

def reply_loading_animation(chat_id, seconds=5):
    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)
        # é¡¯ç¤ºè¼‰å…¥å‹•ç•«
        request = ShowLoadingAnimationRequest(chatId=chat_id, loadingSeconds=seconds)
        line_bot_api.show_loading_animation(request)


def get_db_connection():
    """å¾é€£ç·šæ± å–å¾—è³‡æ–™åº«é€£ç·š"""
    return db_pool.connection()

def get_user_credentials(user_id):
    """å¾è³‡æ–™åº«å–å¾—ä½¿ç”¨è€…çš„ Google OAuth æ†‘è­‰
    
    åƒæ•¸:
        user_id (str): LINE ä½¿ç”¨è€… ID
    
    å›å‚³:
        Credentials: Google OAuth æ†‘è­‰ç‰©ä»¶ï¼Œè‹¥æœªæ‰¾åˆ°å‰‡å›å‚³ None
    """
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute('SELECT token FROM user_tokens WHERE user_id = %s', (user_id,))
            result = cursor.fetchone()
            if result:
                token_json = json.loads(result[0])
                creds = Credentials.from_authorized_user_info(token_json)
                return creds
    finally:
        conn.close()
    return None

def delete_folder_map(source_id, user_id):
    """å¾è³‡æ–™åº«ä¸­åˆªé™¤æŒ‡å®šçš„è³‡æ–™å¤¾æ˜ å°„é—œä¿‚
    
    åƒæ•¸:
        source_id (str): ä¾†æº IDï¼ˆç¾¤çµ„æˆ–ä½¿ç”¨è€…ï¼‰
        user_id (str): LINE ä½¿ç”¨è€… ID
    """
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            sql = "DELETE FROM folder_map WHERE source_id = %s AND user_id = %s"
            cursor.execute(sql, (source_id, user_id))
        conn.commit()
    finally:
        conn.close()

def get_source_name(source_type, source_id):
    """æ›´æ–°æˆ–å»ºç«‹ä¾†æºåç¨±è¨˜éŒ„
    
    åƒæ•¸:
        source_type (str): ä¾†æºé¡å‹ï¼ˆ'group' æˆ– 'user'ï¼‰
        source_id (str): ä¾†æº ID
    
    å›å‚³:
        str: ä¾†æºåç¨±ï¼Œè‹¥å–å¾—å¤±æ•—å‰‡å›å‚³ None
    """
    logger = logging.getLogger('celery')
    
    try:
        # å¾ LINE API å–å¾—æœ€æ–°åç¨±
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            
            if source_type == 'group':
                group_summary = line_bot_api.get_group_summary(group_id=source_id)
                name = group_summary.group_name
            elif source_type == 'user':
                profile = line_bot_api.get_profile(user_id=source_id)
                name = profile.display_name
            else:
                return None
            logger.info("[LINE] Got source name: type=%s, id=%s, name=%s", 
                       source_type, source_id, name)
            return name
    except Exception as e:
        logger.error("[LINE] Failed to get source name: %s", str(e))
        return None

def get_or_create_folder_by_name(drive_service, folder_name, parent_id=None):
    """
    åœ¨æŒ‡å®š parent_id (æˆ–æ ¹ç›®éŒ„) ä¸‹ï¼Œå°‹æ‰¾æˆ–å»ºç«‹åç‚º folder_name çš„è³‡æ–™å¤¾ï¼Œä¸¦å›å‚³è©²è³‡æ–™å¤¾çš„ IDã€‚
    """
    logger = logging.getLogger('celery')
    if parent_id:
        query = (
            f"mimeType='application/vnd.google-apps.folder' "
            f"and name='{folder_name}' "
            f"and '{parent_id}' in parents "
            f"and trashed=false"
        )
        logger.info("[DRIVE] Searching in parent_id=%s for folder_name=%s", parent_id, folder_name)
    else:
        query = (
            f"mimeType='application/vnd.google-apps.folder' "
            f"and name='{folder_name}' "
            f"and 'root' in parents "
            f"and trashed=false"
        )
        logger.info("[DRIVE] Searching in 'root' for folder_name=%s", folder_name)

    response = drive_service.files().list(
        q=query,
        spaces='drive'
    ).execute()

    folders = response.get('files', [])
    
    logger.info("[DRIVE] Found folders:")
    for f in folders:
        logger.info(" - %s | %s", f.get('id'), f.get('name'))

    if folders:
        folder_id = folders[0]['id']
        logger.info("[DRIVE] Using existing folder: %s", folder_id)
        return folder_id

    # è‹¥æ²’æœ‰ï¼Œå‰‡å»ºç«‹æ–°çš„è³‡æ–™å¤¾
    metadata = {
        'name': folder_name,
        'mimeType': 'application/vnd.google-apps.folder',
    }
    if parent_id:
        metadata['parents'] = [parent_id]

    folder = drive_service.files().create(body=metadata, fields='id').execute()
    return folder.get('id')

def get_or_create_folder_for_source_id(source_type, source_id, target_user_id, drive_service, logger):
    """
    åœ¨ `folder_map(source_id, user_id)` è£¡æ‰¾/å»ºæ­¤ (ç¾¤çµ„, ä½¿ç”¨è€…) çš„å°ˆå±¬è³‡æ–™å¤¾ã€‚
    å¦‚æœä¸å­˜åœ¨ï¼Œå°±åœ¨è©²ä½¿ç”¨è€…é›²ç«¯ä¸­ã€ŒLineBot/ç¾¤çµ„åç¨±ã€åº•ä¸‹å»ºç«‹ä¸¦å›å­˜ DBã€‚

    å›å‚³è³‡æ–™å¤¾ ID (str) æˆ– None è¡¨ç¤ºå¤±æ•—ã€‚
    """
    # å–å¾—ç¾¤çµ„æˆ–ä½¿ç”¨è€…åç¨±ï¼ˆè‹¥ç„¡æ³•å–å¾—ï¼Œå°±ç”¨ source_idï¼‰
    folder_name = get_source_name(source_type, source_id) or source_id

    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # æ‰‹å‹•é–‹å§‹äº¤æ˜“
            cursor.execute("START TRANSACTION")

            # 1) å˜—è©¦å¾ folder_map æŸ¥è©¢ (source_id, target_user_id) æ˜¯å¦å·²å­˜åœ¨
            select_sql = """
                SELECT folder_id 
                FROM folder_map
                WHERE source_id = %s
                  AND user_id = %s
                FOR UPDATE
            """
            cursor.execute(select_sql, (source_id, target_user_id))
            row = cursor.fetchone()

            if row:
                # å·²æœ‰è³‡æ–™ â†’ ç›´æ¥ç”¨ç¾æœ‰çš„ folder_id
                folder_id = row[0]
                logger.info(f"[RowLock] Folder exists in DB: {folder_id} (source_id={source_id}, user={target_user_id})")
            else:
                # æ²’æœ‰è³‡æ–™ â†’ å»ºæ–°çš„è³‡æ–™å¤¾

                # å…ˆåœ¨è©²ä½¿ç”¨è€…é›²ç«¯ä¸‹ï¼Œæ‰¾/å»º "LineBot" è³‡æ–™å¤¾
                linebot_folder_id = get_or_create_folder_by_name(drive_service, 'LineBot', parent_id=None)
                # å†åœ¨ "LineBot" è£¡å»ºç¾¤çµ„è³‡æ–™å¤¾
                folder_id = get_or_create_folder_by_name(drive_service, folder_name, parent_id=linebot_folder_id)

                logger.info(f"[RowLock] Created new group folder in user {target_user_id} drive: {folder_id}")

                # å¯«å…¥ DB
                insert_sql = """
                    INSERT INTO folder_map (source_id, user_id, folder_id)
                    VALUES (%s, %s, %s)
                """
                cursor.execute(insert_sql, (source_id, target_user_id, folder_id))
            
            # æäº¤äº¤æ˜“ï¼Œé‡‹æ”¾é–
            conn.commit()
            return folder_id

    except Exception as e:
        conn.rollback()
        logger.error(f"Failed to create/get folder (source_id={source_id}, user={target_user_id}): {e}")
        return None

    finally:
        conn.close()

@celery.task(
    time_limit=300,
    soft_time_limit=270,
    autoretry_for=(ConnectionError, SoftTimeLimitExceeded, HttpError, ),
    retry_kwargs={'max_retries': 3, 'countdown': 10},
    retry_backoff=True,
    bind=True
)
def upload_file_to_drive_task(self, dist_path, dist_name, source_type, source_id, target_user_id, reply_token=None,retry=False):
    """ä¸Šå‚³æª”æ¡ˆåˆ°ä½¿ç”¨è€…çš„ Google Drive
    
    åƒæ•¸:
        self: Celery task ç‰©ä»¶
        dist_path (str): æš«å­˜æª”æ¡ˆè·¯å¾‘
        dist_name (str): ç›®æ¨™æª”æ¡ˆåç¨±
        source_type (str): ä¾†æºé¡å‹ï¼ˆ'group' æˆ– 'user'ï¼‰
        source_id (str): ä¾†æº ID
        target_user_id (str): ç›®æ¨™ä½¿ç”¨è€… ID
        reply_token (str): å›æ‡‰ token
    """
    current_retry = self.request.retries  # é€™æ¬¡é€²åˆ° except block å‰çš„é‡è©¦è¨ˆæ•¸
    max_retry = self.max_retries
    logger = logging.getLogger('celery')
    logger.info("[TASK] Starting upload task: source_type=%s, source_id=%s, target_user_id=%s",
                source_type, source_id, target_user_id)

    uploaded_successfully = False
    try:
        current_name = get_source_name(source_type, source_id)
    except Exception as e:
        logger.error("[TASK] Failed to get source name: %s", str(e))
        current_name = None

    try:
        # 1. å–å¾—è©²ä½¿ç”¨è€…çš„ Google OAuth Credentials
        user_creds = get_user_credentials(target_user_id)
        if not user_creds:
            logger.error("[AUTH] Failed to get credentials for user_id=%s", target_user_id)
            raise UserCredentialsError

        # 2. å»ºç«‹ Drive Service
        service = build('drive', 'v3', credentials=user_creds)

        # 3. å–å¾—(æˆ–å»ºç«‹)é‡å°ã€Œ(ç¾¤çµ„, è©²ä½¿ç”¨è€…)ã€çš„å°ˆå±¬è³‡æ–™å¤¾
        folder_id = get_or_create_folder_for_source_id(source_type, source_id, target_user_id, service, logger)
        if not folder_id:
            logger.error("[DRIVE] Failed to get/create folder for source_id=%s, user_id=%s",
                        source_id, target_user_id)
            raise Exception

        # åœ¨ä¸Šå‚³å‰æª¢æŸ¥ä¸¦æ›´æ–°è³‡æ–™å¤¾åç¨±
        
        if current_name:
            try:
                # å…ˆå–å¾—ç¾æœ‰è³‡æ–™å¤¾è³‡è¨Š
                folder_metadata = service.files().get(fileId=folder_id, fields='name').execute()
                existing_name = folder_metadata.get('name')
                
                # åªåœ¨åç¨±ä¸åŒæ™‚æ‰æ›´æ–°
                if existing_name != current_name:
                    service.files().update(
                        fileId=folder_id,
                        body={'name': current_name}
                    ).execute()
                    logger.info(f"Updated folder name: {existing_name} -> {current_name}")
                else:
                    logger.debug(f"Folder name unchanged: {existing_name}")
            except Exception as e:
                logger.warning(f"Failed to update folder name: {str(e)}")

        # 4. ä¸Šå‚³æª”æ¡ˆ
        media = MediaFileUpload(dist_path, chunksize=1024*1024, resumable=True)
        file_metadata = {
            'name': dist_name,
            'parents': [folder_id]
        }
        file = service.files().create(
            body=file_metadata,
            media_body=media
        ).execute()
        file_id = file.get('id')

        # è¨˜éŒ„ä¸Šå‚³æ—¥èªŒ
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, "success")

        logger.info("[DRIVE] Upload successful: file_id=%s, user_id=%s", file_id, target_user_id)
        if reply_token:
            reply_message(reply_token, [TextMessage(text=f"æ¸¬è©¦åœ–ç‰‡å·²æˆåŠŸä¸Šå‚³åˆ°æ‚¨çš„ Google Drive\né€£çµ: https://drive.google.com/file/d/{file_id}/view?usp=sharing")])
        
        uploaded_successfully = True

    except SoftTimeLimitExceeded:
        logger.error("[TASK] Soft time limit exceeded for user_id=%s", target_user_id)
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, f"timeout{current_retry}/{max_retry}")
        raise

    except ConnectionError as exc:
        logger.error("[NETWORK] Upload failed for user_id=%s: %s", target_user_id, str(exc))
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, f"connection_error{current_retry}/{max_retry}")
        raise

    except HttpError as e:
        if e.resp.status == 404:
            logger.warning("[DRIVE] 404 error: Folder might be deleted. Removing folder_map: %s", str(e))
            delete_folder_map(source_id, target_user_id)
        logger.error("[DRIVE] Upload failed for user_id=%s: %s", target_user_id, str(e))
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, f"http_error{current_retry}/{max_retry}")
        raise

    except UserCredentialsError:
        # è¨˜éŒ„ä¸Šå‚³å¤±æ•—æ—¥èªŒ
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, f"user_credentials_error")
        if reply_token:
            reply_message(reply_token, [TextMessage(text="Google å¸³è™Ÿèªè­‰å¤±æ•—ï¼Œè«‹é‡æ–°ç¶å®š")])
        raise

    except Exception as e:
        logger.error("[TASK] Unexpected error for user_id=%s: %s", target_user_id, str(e))
        if reply_token:
            reply_message(reply_token, [TextMessage(text="ä¸Šå‚³å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")])
        
        # è¨˜éŒ„ä¸Šå‚³å¤±æ•—æ—¥èªŒ
        if not retry:
            log_upload(target_user_id, dist_name, source_type, source_id, current_name, f"unknown_error")
        raise

    finally:
        if uploaded_successfully:
            logger.info("[TASK] Upload completed, keeping temp file: %s", dist_path)
        else:
            logger.info("[TASK] Keeping temp file (upload failed): %s", dist_path)

def log_upload(user_id, file_name, source_type, source_id, source_name, status):
    """è¨˜éŒ„ä¸Šå‚³æ—¥èªŒ"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            sql = "INSERT INTO upload_logs (user_id, file_name, source_type, source_id, source_name, status) VALUES (%s, %s, %s, %s, %s, %s)"
            cursor.execute(sql, (user_id, file_name, source_type, source_id, source_name, status))
        conn.commit()
    finally:
        conn.close()

@celery.task
def clean_temp_file(results, dist_path):
    """æ¸…ç†æš«å­˜æª”æ¡ˆï¼ˆCelery chord çš„å›èª¿å‡½æ•¸ï¼‰
    
    åƒæ•¸:
        results: chord group çš„åŸ·è¡Œçµæœ
        dist_path (str): è¦åˆªé™¤çš„æš«å­˜æª”æ¡ˆè·¯å¾‘
    """
    logger = logging.getLogger('celery')
    # (å¯é¸) logger.info(f"chord group results: {results}")

    if os.path.exists(dist_path):
        try:
            os.remove(dist_path)
            logger.info("[CLEANUP] File deleted: %s", dist_path)
        except OSError as e:
            logger.error("[CLEANUP] Failed to delete file: %s", str(e))
    else:
        logger.info("[CLEANUP] File does not exist: %s", dist_path)

@celery.task
def check_google_status(reply_token, line_user_id):
    logger = logging.getLogger('celery')
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # æª¢æŸ¥æ˜¯å¦æœ‰ç¶å®šè¨˜éŒ„
            cursor.execute('SELECT id FROM user_tokens WHERE user_id = %s', (line_user_id,))
            token_row = cursor.fetchone()
            
            if token_row:
                template_message = TemplateMessage(
                    alt_text='Google å¸³è™Ÿç‹€æ…‹',
                    template=ButtonsTemplate(
                        title='Google å¸³è™Ÿç‹€æ…‹',
                        text='âœ… æ‚¨çš„ Google å¸³è™Ÿç¶å®šç‹€æ…‹æ­£å¸¸',
                        actions=[
                            MessageAction(
                                label='è§£é™¤ç¶å®š',
                                text='!unbindgoogle'
                            )
                        ]
                    )
                )
                reply_message(reply_token, [template_message])
            else:
                template_message = TemplateMessage(
                    alt_text='Google å¸³è™Ÿç‹€æ…‹',
                    template=ButtonsTemplate(
                        title='Google å¸³è™Ÿç‹€æ…‹',
                        text='â— æ‚¨å°šæœªç¶å®š Google å¸³è™Ÿ',
                        actions=[
                            MessageAction(
                                label='ç«‹å³ç¶å®š',
                                text='!bindgoogle'
                            )
                        ]
                    )
                )
                reply_message(reply_token, [template_message])
    except Exception as e:
        logger.error(f"æª¢æŸ¥ Google ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        template_message = TemplateMessage(
            alt_text='Google å¸³è™Ÿç‹€æ…‹',
            template=ButtonsTemplate(
                title='ç³»çµ±éŒ¯èª¤',
                text='æª¢æŸ¥ Google å¸³è™Ÿç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦',
                actions=[
                    MessageAction(
                        label='é‡è©¦',
                        text='!checkgoogle'
                    )
                ]
            )
        )
        reply_message(reply_token, [template_message])
    finally:
        conn.close()

@celery.task(bind=True, max_retries=3, default_retry_delay=5)
def download_line_file_task(self, message_id, ext, filename=None):
    """
    å¾ LINE Messaging API ä¸‹è¼‰æª”æ¡ˆï¼Œä¸¦ä¿å­˜åˆ°æš«å­˜è·¯å¾‘ã€‚
    è‹¥ä¸‹è¼‰æˆ–å¯«æª”éç¨‹å‡ºç¾ä»»ä½•ä¾‹å¤–ï¼Œæœƒè‡ªå‹•é‡è©¦ (æœ€å¤š 3 æ¬¡)ã€‚
    """
    try:
        with ApiClient(configuration) as api_client:
            line_bot_blob_api = MessagingApiBlob(api_client)
            message_content = line_bot_blob_api.get_message_content(message_id=message_id)
            if not message_content:
                raise ValueError("ç„¡æ³•å–å¾—æª”æ¡ˆå…§å®¹ï¼Œmessage_content ç‚º Noneã€‚")

            # è‹¥éœ€è¦ .read() å°±è‡ªè¡ŒåŠ ä¸Šï¼š content_data = message_content.read()
            content_data = message_content

            with tempfile.NamedTemporaryFile(dir=STATIC_TMP_PATH, prefix=f'{ext}-', delete=False) as tf:
                tf.write(content_data)
                tempfile_path = tf.name

        # ç”Ÿæˆæ™‚é–“æˆ³
        timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')

        # å¾è‡¨æ™‚æª”æ¡ˆè·¯å¾‘ç²å–åŸºæœ¬æª”åï¼ˆä¸å«è·¯å¾‘ï¼‰
        temp_basename = os.path.basename(tempfile_path)

        # æ ¹æ“šæª”æ¡ˆé¡å‹è™•ç†
        if ext == 'file':
            if filename:
                # å¦‚æœæœ‰æä¾›æª”åï¼Œä½¿ç”¨å®ƒ
                dist_path = f"{STATIC_TMP_PATH}/{timestamp}_{filename}"
            else:
                # å¦‚æœæ²’æœ‰æä¾›æª”åï¼Œç›´æ¥ä½¿ç”¨è‡¨æ™‚æª”å
                dist_path = f"{STATIC_TMP_PATH}/{timestamp}_{temp_basename}"
        else:
            # å°æ–¼åª’é«”æª”æ¡ˆï¼Œåœ¨è‡¨æ™‚æª”ååŸºç¤ä¸ŠåŠ ä¸Šå‰¯æª”å
            dist_path = f"{STATIC_TMP_PATH}/{timestamp}_{temp_basename}.{ext}"

        # é‡å‘½åè‡¨æ™‚æª”æ¡ˆ
        os.rename(tempfile_path, dist_path)

        # ç›´æ¥å¾ dist_path æå–æª”å
        dist_name = os.path.basename(dist_path)

        return dist_path, dist_name

    except Exception as e:
        raise self.retry(exc=e, countdown=5)
    
@celery.task
def handle_upload_task(download_result, event_data):
    """
    å–ä»£åŸæœ¬åœ¨ä¸»ç¨‹å¼çš„ handle_upload() å‡½å¼ï¼š
    1) æ ¹æ“š download_result æ‹¿ dist_path, dist_name
    2) åˆ¤æ–·ä¾†æºæ˜¯ user / groupï¼Œé€²è¡Œä¸Šå‚³
    3) ä¸Šå‚³å®Œå¾Œ chord callback -> clean_temp_file
    """
    dist_path, dist_name = download_result
    source_type = event_data['source_type']
    source_id = event_data['source_id']
    reply_token = event_data.get('reply_token', None)

    # log å¯æ”¹ç‚ºä½ çš„ logger
    print(f"[TASK] Creating upload tasks for {source_type}: id={source_id}")

    if source_type == 'user':
        # æŸ¥ä½¿ç”¨è€… debug_mode (ç¯„ä¾‹)
        debug_mode = False
        with get_db_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute('SELECT debug_mode FROM user_status WHERE user_id = %s', (source_id,))
                result = cursor.fetchone()
                debug_mode = (result[0] if result else False)

        # è‹¥è¦åœ¨ worker ç«¯ç”¨ reply_token å›æ‡‰, è¦æ³¨æ„ token 30ç§’æœ‰æ•ˆ; å»ºè­°æ”¹æˆ push_message
        if debug_mode:
            reply_loading_animation(source_id, 15)
        else:
            reply_token = None

        # å–®ä¸€ä»»å‹™ + clean_temp_file
        task = upload_file_to_drive_task.s(dist_path, dist_name, source_type, source_id, source_id, reply_token)
        callback = clean_temp_file.s(dist_path)
        return chord(task)(callback)

    else:  # group
        bound_users = []
        with get_db_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute('SELECT user_id FROM group_users WHERE group_id = %s', (source_id,))
                bound_users = cursor.fetchall()

        if bound_users:
            task_list = [
                upload_file_to_drive_task.s(dist_path, dist_name, source_type, source_id, row[0])
                for row in bound_users
            ]
            callback = clean_temp_file.s(dist_path)
            return chord(group(task_list))(callback)
        else:
            # ç„¡ç¶å®šä½¿ç”¨è€… -> ç›´æ¥åˆªæ‰æš«å­˜æª”
            if os.path.exists(dist_path):
                os.remove(dist_path)
            print(f"[CLEANUP] No bound users, deleted temp file: {dist_path}")
            return "OK"

@celery.task
def clean_old_upload_logs(days=7):
    """æ¸…ç†è¶…éæŒ‡å®šå¤©æ•¸çš„ä¸Šå‚³æ—¥èªŒ"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute('DELETE FROM upload_logs WHERE upload_time < NOW() - INTERVAL %s DAY', (days,))
        conn.commit()
    finally:
        conn.close()

@celery.task
def clean_tmp_logs(minutes=30):
    """æ¸…ç†æš«å­˜æ—¥èªŒæª”æ¡ˆ"""
    now = time.time()
    cutoff = now - (minutes * 60)
    
    for filename in os.listdir(STATIC_LOGS_PATH):
        file_path = os.path.join(STATIC_LOGS_PATH, filename)
        if os.path.isfile(file_path):
            file_mtime = os.path.getmtime(file_path)
            if file_mtime < cutoff:
                os.remove(file_path)
                print(f"Deleted {file_path}")
    
@celery.task
def showlog_task(reply_token, user_id):
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute('SELECT file_name, upload_time, source_type, source_name, status FROM upload_logs WHERE user_id = %s ORDER BY upload_time DESC', (user_id,))
            logs = cursor.fetchall()
            
            if logs:
                full_logs = []
                for log in logs:
                    file_name, upload_time, source_type, source_name, status = log
                    full_logs.append(f"{file_name}\næ™‚é–“: {upload_time}\nä¾†æº: {source_type} ({source_name})\nç‹€æ…‹: {status}\n\n")
                full_text = "".join(full_logs)
                
                if len(full_text) > 1000:
                    reply_text = "æ—¥èªŒéé•·ï¼Œè«‹é»æ“ŠæŸ¥çœ‹å®Œæ•´ç´€éŒ„(æœ‰æ•ˆæœŸ30åˆ†é˜)\n\n" + full_text[:20] + "..."
                    with tempfile.NamedTemporaryFile(delete=False, dir=STATIC_LOGS_PATH, suffix=".txt") as temp_file:
                        temp_file.write(full_text.encode('utf-8'))
                        temp_file_name = os.path.basename(temp_file.name)
                    
                    # å‡è¨­æ‚¨æœ‰ä¸€å€‹ä¼ºæœå™¨å¯ä»¥æä¾›é€™å€‹æª”æ¡ˆ
                    file_url = f"https://{BASE_URI}/linebot/logs/{temp_file_name}"
                    button_template = TemplateMessage(
                        alt_text="ä¸Šå‚³æ—¥èªŒ",
                        template=ButtonsTemplate(
                            title="ä¸Šå‚³æ—¥èªŒ",
                            text=reply_text,
                            actions=[
                                URIAction(
                                    label="æŸ¥çœ‹å®Œæ•´ç´€éŒ„",
                                    uri=file_url
                                )
                            ]
                        )
                    )
                    reply_message(reply_token, [button_template])
                else:
                    reply_message(reply_token, [TextMessage(text=full_text)])


            else:
                reply_message(reply_token, [TextMessage(text="æ‚¨å°šæœªä¸Šå‚³ä»»ä½•æª”æ¡ˆã€‚")])
    finally:
        conn.close()

@celery.task
def handle_list_group_task(reply_token, user_id):
    logger = logging.getLogger('celery')
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # å…ˆæŸ¥è©¢å€‹äººè³‡æ–™å¤¾
            logger.info("[LISTGROUP] Querying personal folder")
            cursor.execute('''
                SELECT 
                    'personal' as type,
                    fm.source_id,
                    fm.folder_id
                FROM folder_map fm
                WHERE fm.source_id = %s 
                    AND fm.user_id = %s
                UNION ALL
                SELECT 
                    'group' as type,
                    gu.group_id,
                    fm2.folder_id
                FROM group_users gu 
                LEFT JOIN folder_map fm2
                    ON fm2.source_id = gu.group_id 
                    AND fm2.user_id = gu.user_id 
                WHERE gu.user_id = %s
            ''', (user_id, user_id, user_id))
            rows = cursor.fetchall()
            
        if not rows:
            logger.info("[LISTGROUP] No folders found for user_id=%s", user_id)
            reply_text = "æ‚¨å°šæœªå»ºç«‹ä»»ä½•è³‡æ–™å¤¾ã€‚"
            reply_message(reply_token, [TextMessage(text=reply_text)])
        
        columns = []
        
        # è™•ç†æŸ¥è©¢çµæœ
        for i, row in enumerate(rows):
            row_type, source_id, folder_id = row
            if row_type == 'personal':
                display_name = "å€‹äººè³‡æ–™å¤¾"
            else:
                display_name = get_source_name('group', source_id) or source_id

            logger.info("[LISTGROUP] Processing group %d: id=%s, name=%s, folder_id=%s", 
                        i, source_id, display_name, folder_id)
            
            # å»ºç«‹ Carousel æ¬„ä½
            if i < 9 or (i == 9 and len(rows) <= 10):  # å‰9å€‹æˆ–æœ€å¾Œä¸€å€‹ï¼ˆå¦‚æœç¸½æ•¸<=10ï¼‰
                actions = []
                if folder_id:
                    actions.append(URIAction(
                        label='é–‹å•Ÿè³‡æ–™å¤¾',
                        uri=f"https://drive.google.com/drive/folders/{folder_id}?authuser=0&openExternalBrowser=1"
                    ))
                else:
                    actions.append(MessageAction(
                        label='å°šæœªå»ºç«‹è³‡æ–™å¤¾',
                        text='å°šæœªå»ºç«‹å°æ‡‰çš„ Google Drive è³‡æ–™å¤¾'
                    ))
                
                columns.append(CarouselColumn(
                    title=display_name[:40],  # LINEé™åˆ¶æ¨™é¡Œé•·åº¦
                    text=f"{source_id}"[:60],  # LINEé™åˆ¶å…§æ–‡é•·åº¦
                    actions=actions
                ))
            elif i == 9:  # ç¬¬10å€‹ä¸”ç¸½æ•¸>10
                # æ–°å¢ã€Œé¡¯ç¤ºæ›´å¤šã€æŒ‰éˆ•ï¼ŒåŠ å…¥å¿…è¦çš„ label åƒæ•¸
                columns.append(CarouselColumn(
                    title="é‚„æœ‰æ›´å¤šç¾¤çµ„",
                    text=f"é‚„æœ‰ {len(rows) - 9} å€‹ç¾¤çµ„",
                    actions=[
                        MessageAction(
                            label="é¡¯ç¤ºå®Œæ•´æ¸…å–®",  # åŠ å…¥å¿…è¦çš„ label åƒæ•¸
                            text='!showcompletegroup'
                        )
                    ]
                ))
                break
            
        carousel_template = CarouselTemplate(columns=columns)
        template_message = TemplateMessage(
            alt_text='æ‚¨çš„ç¾¤çµ„åˆ—è¡¨',
            template=carousel_template
        )
        logger.info("[LISTGROUP] Sending carousel template with %d columns", len(columns))

        reply_message(reply_token, [template_message])
    except Exception as e:
        logger.error(f"[LISTGROUP] Error processing listgroup command: {str(e)}")
        raise
    finally:
        conn.close()

@celery.task
def handle_update_folder_task(reply_token, user_id):
    """æ›´æ–°ä½¿ç”¨è€…ç¶å®šç¾¤çµ„çš„è³‡æ–™å¤¾åç¨±
    
    æ­¤ä»»å‹™æœƒæª¢æŸ¥ä½¿ç”¨è€…ç¶å®šçš„æ‰€æœ‰ç¾¤çµ„è³‡æ–™å¤¾ï¼Œä¸¦ç¢ºä¿è³‡æ–™å¤¾åç¨±èˆ‡ç¾¤çµ„åç¨±ä¸€è‡´ã€‚
    å…·é«”æª¢æŸ¥å…§å®¹:
    1. æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨ (404éŒ¯èª¤è¡¨ç¤ºè³‡æ–™å¤¾ä¸å­˜åœ¨)
    2. æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦æœ‰æ•ˆ (æ˜¯å¦å¯ä»¥è¨ªå•æˆ–å·²è¢«åˆªé™¤)
    3. æª¢æŸ¥è³‡æ–™å¤¾åç¨±æ˜¯å¦èˆ‡ç¾¤çµ„åç¨±ä¸€è‡´
    
    åƒæ•¸:
        reply_token (str): LINE å›è¦†ä»¤ç‰Œ
        user_id (str): LINE ä½¿ç”¨è€… ID
    """
    logger = logging.getLogger('celery')
    logger.info("[UPDATEFOLDER] é–‹å§‹æª¢æŸ¥ä½¿ç”¨è€… %s çš„ç¾¤çµ„è³‡æ–™å¤¾", user_id)
    
    # å–å¾—ä½¿ç”¨è€…çš„ Google OAuth æ†‘è­‰
    user_creds = get_user_credentials(user_id)
    if not user_creds:
        logger.error("[UPDATEFOLDER] ç„¡æ³•ç²å–ä½¿ç”¨è€… %s çš„ Google æ†‘è­‰", user_id)
        reply_message(reply_token, [TextMessage(text="æ‚¨å°šæœªç¶å®š Google å¸³è™Ÿï¼Œè«‹å…ˆè¼¸å…¥ !bindgoogle")])
        return
    
    # å»ºç«‹ Drive Service
    service = build('drive', 'v3', credentials=user_creds)
    
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # æŸ¥è©¢ä½¿ç”¨è€…ç¶å®šçš„æ‰€æœ‰ç¾¤çµ„èˆ‡å°æ‡‰è³‡æ–™å¤¾
            logger.info("[UPDATEFOLDER] æŸ¥è©¢ä½¿ç”¨è€… %s çš„æ‰€æœ‰ç¾¤çµ„èˆ‡è³‡æ–™å¤¾æ˜ å°„", user_id)
            cursor.execute('''
                SELECT gu.group_id, fm.folder_id, gi.name 
                FROM group_users gu 
                LEFT JOIN folder_map fm 
                    ON fm.source_id = gu.group_id 
                    AND fm.user_id = gu.user_id 
                LEFT JOIN group_info gi
                    ON gi.group_id = gu.group_id
                WHERE gu.user_id = %s AND fm.folder_id IS NOT NULL
                ''', (user_id,))
                
            groups = cursor.fetchall()
            
            if not groups:
                reply_message(reply_token, [TextMessage(text="æ‚¨å°šæœªç¶å®šä»»ä½•ç¾¤çµ„æˆ–å°šæœªå»ºç«‹ç¾¤çµ„è³‡æ–™å¤¾ã€‚")])
                return
            
            updated_count = 0        # å·²æ›´æ–°çš„è³‡æ–™å¤¾æ•¸é‡
            not_found_count = 0      # æ‰¾ä¸åˆ°çš„è³‡æ–™å¤¾æ•¸é‡
            no_change_count = 0      # ç„¡éœ€æ›´æ–°çš„è³‡æ–™å¤¾æ•¸é‡
            error_count = 0          # ç™¼ç”ŸéŒ¯èª¤çš„è³‡æ–™å¤¾æ•¸é‡
            access_error_count = 0   # è¨ªå•æ¬Šé™éŒ¯èª¤çš„è³‡æ–™å¤¾æ•¸é‡
            
            update_results = []
            
            # æª¢æŸ¥æ¯å€‹ç¾¤çµ„çš„è³‡æ–™å¤¾
            for group_id, folder_id, stored_name in groups:
                try:
                    # 1. æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨èˆ‡æ˜¯å¦æœ‰æ•ˆ - é€éå˜—è©¦ç²å–è³‡æ–™å¤¾å…ƒæ•¸æ“š
                    try:
                        # å˜—è©¦ç²å–è³‡æ–™å¤¾è©³ç´°è³‡è¨Šï¼ŒåŒ…æ‹¬è³‡æ–™å¤¾åç¨±ã€æ¬Šé™ç­‰
                        folder_metadata = service.files().get(
                            fileId=folder_id, 
                            fields='name,capabilities,trashed'
                        ).execute()
                        
                        folder_name = folder_metadata.get('name')
                        is_trashed = folder_metadata.get('trashed', False)
                        can_edit = folder_metadata.get('capabilities', {}).get('canEdit', False)
                        
                        # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å·²è¢«ç§»åˆ°åƒåœ¾æ¡¶
                        if is_trashed:
                            logger.warning("[UPDATEFOLDER] è³‡æ–™å¤¾å·²è¢«ç§»åˆ°åƒåœ¾æ¡¶ (folder_id=%s, group_id=%s)",
                                        folder_id, group_id)
                            update_results.append(f"ğŸ—‘ï¸ è³‡æ–™å¤¾å·²è¢«ç§»åˆ°åƒåœ¾æ¡¶: {stored_name or group_id}")
                            not_found_count += 1
                            continue
                            
                        # æª¢æŸ¥æ˜¯å¦æœ‰ç·¨è¼¯æ¬Šé™
                        if not can_edit:
                            logger.warning("[UPDATEFOLDER] æ²’æœ‰è³‡æ–™å¤¾ç·¨è¼¯æ¬Šé™ (folder_id=%s, group_id=%s)",
                                        folder_id, group_id)
                            update_results.append(f"ğŸ”’ æ²’æœ‰ç·¨è¼¯æ¬Šé™: {stored_name or group_id}")
                            access_error_count += 1
                            continue
                            
                        # 2. ç²å–æœ€æ–°çš„ç¾¤çµ„åç¨±ï¼ˆç”¨æ–¼æª¢æŸ¥è³‡æ–™å¤¾åç¨±æ˜¯å¦éœ€è¦æ›´æ–°ï¼‰
                        current_name = get_source_name('group', group_id)
                        
                        if not current_name:
                            logger.warning("[UPDATEFOLDER] ç„¡æ³•ç²å–ç¾¤çµ„ %s çš„åç¨±ï¼Œä½¿ç”¨è³‡æ–™åº«ä¸­çš„åç¨±", group_id)
                            current_name = stored_name or group_id
                        
                        # 3. æª¢æŸ¥è³‡æ–™å¤¾åç¨±æ˜¯å¦èˆ‡ç¾¤çµ„åç¨±ä¸€è‡´
                        if folder_name != current_name:
                            # æ›´æ–°è³‡æ–™å¤¾åç¨±
                            service.files().update(
                                fileId=folder_id,
                                body={'name': current_name}
                            ).execute()
                            logger.info("[UPDATEFOLDER] å·²æ›´æ–°è³‡æ–™å¤¾åç¨±: %s -> %s (folder_id=%s, group_id=%s)",
                                    folder_name, current_name, folder_id, group_id)
                            update_results.append(f"âœ… å·²æ›´æ–°: {folder_name} â†’ {current_name}")
                            updated_count += 1
                        else:
                            logger.info("[UPDATEFOLDER] è³‡æ–™å¤¾åç¨±ç„¡éœ€æ›´æ–°: %s (folder_id=%s, group_id=%s)",
                                    folder_name, folder_id, group_id)
                            no_change_count += 1
                            
                    except HttpError as e:
                        # è™•ç†ä¸åŒé¡å‹çš„ API éŒ¯èª¤
                        if e.resp.status == 404:
                            # è³‡æ–™å¤¾ä¸å­˜åœ¨
                            logger.warning("[UPDATEFOLDER] æ‰¾ä¸åˆ°è³‡æ–™å¤¾ (folder_id=%s, group_id=%s): %s",
                                        folder_id, group_id, str(e))
                            update_results.append(f"âš ï¸ æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {stored_name or group_id}")
                            not_found_count += 1
                            
                            # å¯ä»¥é¸æ“‡å¾æ˜ å°„è¡¨ä¸­åˆªé™¤æ­¤è¨˜éŒ„
                            delete_folder_map(group_id, user_id)
                            logger.info("[UPDATEFOLDER] å·²å¾è³‡æ–™åº«ä¸­åˆªé™¤ä¸å­˜åœ¨çš„è³‡æ–™å¤¾æ˜ å°„è¨˜éŒ„ (folder_id=%s)", folder_id)
                            
                        elif e.resp.status == 403:
                            # æ²’æœ‰æ¬Šé™è¨ªå•
                            logger.warning("[UPDATEFOLDER] æ²’æœ‰æ¬Šé™è¨ªå•è³‡æ–™å¤¾ (folder_id=%s, group_id=%s): %s",
                                        folder_id, group_id, str(e))
                            update_results.append(f"ğŸ”’ æ²’æœ‰è¨ªå•æ¬Šé™: {stored_name or group_id}")
                            access_error_count += 1
                        else:
                            # å…¶ä»– API éŒ¯èª¤
                            logger.error("[UPDATEFOLDER] æ›´æ–°è³‡æ–™å¤¾æ™‚ç™¼ç”Ÿ API éŒ¯èª¤ (folder_id=%s, group_id=%s): %s",
                                        folder_id, group_id, str(e))
                            update_results.append(f"âŒ æ›´æ–°å¤±æ•—: {stored_name or group_id}")
                            error_count += 1
                            
                except Exception as e:
                    # è™•ç†å…¶ä»–æœªé æœŸçš„éŒ¯èª¤
                    logger.error("[UPDATEFOLDER] è™•ç†ç¾¤çµ„ %s è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", group_id, str(e))
                    update_results.append(f"âŒ è™•ç†éŒ¯èª¤: {stored_name or group_id}")
                    error_count += 1
            
            # ç”Ÿæˆå›è¦†è¨Šæ¯
            total = len(groups)
            summary = f"è³‡æ–™å¤¾æª¢æŸ¥å®Œæˆ ({total} å€‹ç¾¤çµ„):\n"
            summary += f"âœ… {updated_count} å€‹å·²æ›´æ–°\n"
            summary += f"âœ“ {no_change_count} å€‹ç„¡éœ€æ›´æ–°\n"
            
            if not_found_count > 0:
                summary += f"âš ï¸ {not_found_count} å€‹æ‰¾ä¸åˆ°æˆ–å·²åˆªé™¤\n"
            if access_error_count > 0:
                summary += f"ğŸ”’ {access_error_count} å€‹æ¬Šé™éŒ¯èª¤\n"
            if error_count > 0:
                summary += f"âŒ {error_count} å€‹ç™¼ç”ŸéŒ¯èª¤\n"
                
            if update_results:
                details = "\n".join(update_results[:10])  # é™åˆ¶æœ€å¤šé¡¯ç¤º10å€‹è©³ç´°çµæœ
                if len(update_results) > 10:
                    details += f"\n(é‚„æœ‰ {len(update_results) - 10} å€‹çµæœæœªé¡¯ç¤º)"
                reply_text = f"{summary}\n\nè©³ç´°çµæœ:\n{details}"
            else:
                reply_text = summary
                
            reply_message(reply_token, [TextMessage(text=reply_text)])
            
    except Exception as e:
        logger.error("[UPDATEFOLDER] æ›´æ–°è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", str(e))
        reply_message(reply_token, [TextMessage(text="æª¢æŸ¥ç¾¤çµ„è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")])
    finally:
        conn.close()

@celery.task
def retry_failed_uploads_task(reply_token, user_id, hours_ago=24):
    """é‡è©¦æŒ‡å®šä½¿ç”¨è€…åœ¨æŒ‡å®šæ™‚é–“å…§å¤±æ•—çš„ä¸Šå‚³
    
    åƒæ•¸:
        reply_token (str): LINE å›è¦†ä»¤ç‰Œ
        user_id (str): LINE ä½¿ç”¨è€… ID
        hours_ago (int): æª¢ç´¢å¤šå°‘å°æ™‚å‰çš„å¤±æ•—è¨˜éŒ„
    """
    logger = logging.getLogger('celery')
    logger.info(f"[RETRY] é–‹å§‹è™•ç†ä½¿ç”¨è€… {user_id} çš„å¤±æ•—ä¸Šå‚³ï¼ˆ{hours_ago}å°æ™‚å…§ï¼‰...")
    
    # é‡è©¦çµæœçµ±è¨ˆ
    results = {
        "æ‰¾åˆ°éœ€é‡è©¦è¨˜éŒ„": 0,
        "æª”æ¡ˆä¸å­˜åœ¨": 0,
        "é‡è©¦æˆåŠŸ": 0,
        "é‡è©¦å¤±æ•—": 0,
        "ç„¡æ³•è™•ç†": 0
    }
    
    # å¾è³‡æ–™åº«ç²å–è©²ä½¿ç”¨è€…çš„å¤±æ•—è¨˜éŒ„
    conn = get_db_connection()
    failed_uploads = []
    try:
        with conn.cursor() as cursor:
            # æŸ¥è©¢ç‰¹å®šä½¿ç”¨è€…çš„å¤±æ•—ä¸Šå‚³è¨˜éŒ„
            cursor.execute("""
                SELECT id, file_name, source_type, source_id, status 
                FROM upload_logs 
                WHERE user_id = %s 
                  AND upload_time > DATE_SUB(NOW(), INTERVAL %s HOUR)
                  AND status NOT LIKE 'success'
                  AND status NOT LIKE 'é‡è©¦æˆåŠŸ'
                ORDER BY upload_time DESC
            """, (user_id, hours_ago))
            failed_uploads = cursor.fetchall()
            results["æ‰¾åˆ°éœ€é‡è©¦è¨˜éŒ„"] = len(failed_uploads)
            logger.info(f"[RETRY] æ‰¾åˆ° {len(failed_uploads)} ç­†å¤±æ•—è¨˜éŒ„")
    
        # è™•ç†æ¯ä¸€ç­†å¤±æ•—è¨˜éŒ„
        for record in failed_uploads:
            record_id, file_name, source_type, source_id, status = record
            logger.info(f"[RETRY] è™•ç†è¨˜éŒ„ ID={record_id}, æª”æ¡ˆ={file_name}")
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            dist_path = os.path.join(STATIC_TMP_PATH, file_name)
            if not os.path.exists(dist_path):
                logger.warning(f"[RETRY] æª”æ¡ˆä¸å­˜åœ¨: {dist_path}")
                results["æª”æ¡ˆä¸å­˜åœ¨"] += 1
                
                # å˜—è©¦æŸ¥æ‰¾åªæœ‰åŸºæœ¬åç¨±åŒ¹é…çš„æª”æ¡ˆ
                base_name = os.path.basename(file_name)
                found = False
                for tmp_file in os.listdir(STATIC_TMP_PATH):
                    if base_name in tmp_file:
                        dist_path = os.path.join(STATIC_TMP_PATH, tmp_file)
                        logger.info(f"[RETRY] æ‰¾åˆ°å¯èƒ½åŒ¹é…çš„æª”æ¡ˆ: {tmp_file}")
                        found = True
                        break
                
                if not found:
                    # æ›´æ–°æ—¥èªŒç‹€æ…‹
                    with conn.cursor() as cursor:
                        cursor.execute(
                            "UPDATE upload_logs SET status = %s WHERE id = %s",
                            (f"æª”æ¡ˆä¸å­˜åœ¨ (é‡è©¦æ–¼ {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')})", record_id)
                        )
                    conn.commit()
                    continue
            
            # é‡è©¦ä¸Šå‚³
            try:
                logger.info(f"[RETRY] å˜—è©¦é‡æ–°ä¸Šå‚³: {file_name}, ä¾†æº: {source_type}/{source_id}")
                
                
                # åŸ·è¡Œä¸Šå‚³ä»»å‹™
                upload_file_to_drive_task(dist_path, file_name, source_type, source_id, user_id)
                
                # æ›´æ–°æ—¥èªŒç‹€æ…‹
                with conn.cursor() as cursor:
                    cursor.execute(
                        "UPDATE upload_logs SET status = %s WHERE id = %s",
                        ("é‡è©¦æˆåŠŸ", record_id)
                    )
                conn.commit()
                results["é‡è©¦æˆåŠŸ"] += 1
                logger.info(f"[RETRY] é‡è©¦ä¸Šå‚³æˆåŠŸ: {file_name}")
                
            except Exception as e:
                logger.error(f"[RETRY] é‡è©¦ä¸Šå‚³å¤±æ•—: {str(e)}")
                results["é‡è©¦å¤±æ•—"] += 1
                
                # æ›´æ–°æ—¥èªŒç‹€æ…‹
                with conn.cursor() as cursor:
                    cursor.execute(
                        "UPDATE upload_logs SET status = %s WHERE id = %s",
                        ("é‡è©¦å¤±æ•—", record_id)
                    )
                conn.commit()
    
    except Exception as e:
        logger.error(f"[RETRY] åŸ·è¡Œè£œä¸Šå‚³ä»»å‹™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    finally:
        conn.close()
    
    # å›å ±çµæœ
    reply_text = f"æ‚¨çš„è£œä¸Šå‚³çµæœï¼š\n"
    reply_text += f"âœ“ æ‰¾åˆ°å¤±æ•—è¨˜éŒ„ï¼š{results['æ‰¾åˆ°éœ€é‡è©¦è¨˜éŒ„']}ç­†\n"
    if results["æ‰¾åˆ°éœ€é‡è©¦è¨˜éŒ„"] > 0:
        reply_text += f"âœ“ æˆåŠŸè£œä¸Šå‚³ï¼š{results['é‡è©¦æˆåŠŸ']}ç­†\n"
        if results["æª”æ¡ˆä¸å­˜åœ¨"] > 0:
            reply_text += f"âœ— æª”æ¡ˆå·²ä¸å­˜åœ¨ï¼š{results['æª”æ¡ˆä¸å­˜åœ¨']}ç­†\n"
        if results["é‡è©¦å¤±æ•—"] > 0:
            reply_text += f"âœ— é‡è©¦å¤±æ•—ï¼š{results['é‡è©¦å¤±æ•—']}ç­†\n"

    
    if reply_token:
        reply_message(reply_token, [TextMessage(text=reply_text)])
    return results

@celery.task
def list_failed_uploads_task(reply_token, user_id, hours_ago=24):
    """åˆ—å‡ºæŒ‡å®šä½¿ç”¨è€…åœ¨æŒ‡å®šæ™‚é–“å…§çš„å¤±æ•—ä¸Šå‚³è¨˜éŒ„
    
    åƒæ•¸:
        reply_token (str): LINE å›è¦†ä»¤ç‰Œ
        user_id (str): LINE ä½¿ç”¨è€… ID
        hours_ago (int): æª¢ç´¢å¤šå°‘å°æ™‚å‰çš„å¤±æ•—è¨˜éŒ„
    """
    logger = logging.getLogger('celery')
    logger.info(f"[LIST_FAILED] é–‹å§‹æŸ¥è©¢ä½¿ç”¨è€… {user_id} çš„å¤±æ•—ä¸Šå‚³ï¼ˆ{hours_ago}å°æ™‚å…§ï¼‰...")
    
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            logger.info("[LIST_FAILED] æŸ¥è©¢ä½¿ç”¨è€…çš„å¤±æ•—ä¸Šå‚³è¨˜éŒ„")
            # æŸ¥è©¢ç‰¹å®šä½¿ç”¨è€…çš„å¤±æ•—ä¸Šå‚³è¨˜éŒ„
            cursor.execute("""
                SELECT id, file_name, upload_time, source_type, source_id, status 
                FROM upload_logs 
                WHERE user_id = %s 
                  AND upload_time > DATE_SUB(NOW(), INTERVAL %s HOUR)
                  AND status NOT LIKE 'success'
                  AND status NOT LIKE 'é‡è©¦æˆåŠŸ'
                ORDER BY upload_time DESC
            """, (user_id, hours_ago))
            logger.info("[LIST_FAILED] å–å¾—å¤±æ•—è¨˜éŒ„")
            failed_logs = cursor.fetchall()
            logger.info("[LIST_FAILED] å–å¾—å¤±æ•—è¨˜éŒ„è‡³è®Šæ•¸")
            
            
            # æº–å‚™å›è¦†è¨Šæ¯
            if failed_logs is None or len(failed_logs) == 0:
                reply_text = f"éå» {hours_ago} å°æ™‚å…§æ²’æœ‰å¤±æ•—çš„ä¸Šå‚³ç´€éŒ„ã€‚"
                reply_message(reply_token, [TextMessage(text=reply_text)])
                logger.info("[LIST_FAILED] ç„¡å¤±æ•—è¨˜éŒ„ï¼Œè¿”å›ç©ºè¨Šæ¯")
                return
            
            # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
            count_by_source_type = {}  # ä¾ä¾†æºé¡å‹çµ±è¨ˆ
            count_by_status = {}       # ä¾ç‹€æ…‹çµ±è¨ˆ
            
            # æº–å‚™è©³ç´°åˆ—è¡¨
            logs_text = []
            for i, (record_id, file_name, upload_time, source_type, source_name, status) in enumerate(failed_logs, 1):
                # æ›´æ–°çµ±è¨ˆ
                count_by_source_type[source_type] = count_by_source_type.get(source_type, 0) + 1
                
                # çµ±è¨ˆå„ç¨®éŒ¯èª¤é¡å‹
                error_type = "å…¶ä»–éŒ¯èª¤"
                if "connection_error" in status:
                    error_type = "é€£ç·šéŒ¯èª¤"
                elif "timeout" in status:
                    error_type = "è¶…æ™‚éŒ¯èª¤"
                elif "user_credentials_error" in status:
                    error_type = "èªè­‰éŒ¯èª¤"
                elif "http_error" in status:
                    error_type = "APIéŒ¯èª¤"
                elif "æª”æ¡ˆä¸å­˜åœ¨" in status:
                    error_type = "æª”æ¡ˆä¸å­˜åœ¨"
                
                count_by_status[error_type] = count_by_status.get(error_type, 0) + 1
                
                # çµ„åˆè©³ç´°è¨˜éŒ„
                logs_text.append(
                    f"{i}. æª”æ¡ˆï¼š{file_name}\n"
                    f"   æ™‚é–“ï¼š{upload_time}\n"
                    f"   ä¾†æºï¼š{source_type} ({source_name})\n"
                    f"   ç‹€æ…‹ï¼š{status}\n"
                )
            
            # çµ„åˆæ‘˜è¦èˆ‡è©³ç´°è¨˜éŒ„
            summary = f"éå» {hours_ago} å°æ™‚å…§å¤±æ•—ä¸Šå‚³è¨˜éŒ„æ‘˜è¦ï¼š\n"
            summary += f"â€¢ ç¸½è¨ˆå¤±æ•—è¨˜éŒ„ï¼š{len(failed_logs)}ç­†\n"
            
            # ä¾†æºé¡å‹æ‘˜è¦
            summary += "\nã€ä¾ä¾†æºé¡å‹ã€‘\n"
            for source_type, count in count_by_source_type.items():
                summary += f"â€¢ {source_type}: {count}ç­†\n"
            
            # éŒ¯èª¤é¡å‹æ‘˜è¦
            summary += "\nã€ä¾éŒ¯èª¤é¡å‹ã€‘\n"
            for error_type, count in count_by_status.items():
                summary += f"â€¢ {error_type}: {count}ç­†\n"
            
            summary += "\nè¦é‡è©¦é€™äº›å¤±æ•—çš„ä¸Šå‚³ï¼Œè«‹ä½¿ç”¨ !retryupload æŒ‡ä»¤ã€‚\n"
            
            # åˆä½µè¨Šæ¯ï¼Œå¦‚æœå¤ªé•·ï¼Œå°±å»ºç«‹æš«å­˜æª”ä¸¦æä¾›é€£çµ
            full_text = summary + "\nè©³ç´°è¨˜éŒ„ï¼š\n\n" + "\n".join(logs_text)
            
            if len(full_text) > 1000:
                with tempfile.NamedTemporaryFile(delete=False, dir=STATIC_LOGS_PATH, suffix=".txt") as temp_file:
                    temp_file.write(full_text.encode('utf-8'))
                    temp_file_name = os.path.basename(temp_file.name)
                
                # ç”¢ç”Ÿæª”æ¡ˆ URL
                file_url = f"https://{BASE_URI}/linebot/logs/{temp_file_name}"
                
                # ä½¿ç”¨ ButtonsTemplate è®“ç”¨æˆ¶å¯ä»¥æŸ¥çœ‹å®Œæ•´è¨˜éŒ„
                button_template = TemplateMessage(
                    alt_text="å¤±æ•—ä¸Šå‚³è¨˜éŒ„",
                    template=ButtonsTemplate(
                        title="å¤±æ•—ä¸Šå‚³è¨˜éŒ„",
                        text="è©³ç´°è¨˜éŒ„è«‹é»ä¸‹æ–¹æŒ‰éˆ•æŸ¥çœ‹å®Œæ•´å…§å®¹",
                        actions=[
                            URIAction(
                                label="æŸ¥çœ‹å®Œæ•´è¨˜éŒ„",
                                uri=file_url
                            ),
                            MessageAction(
                                label="é‡è©¦ä¸Šå‚³",
                                text=f"!retryupload {hours_ago}"
                            )
                        ]
                    )
                )
                reply_message(reply_token, [button_template])
            else:
                # ç›´æ¥å›è¦†å®Œæ•´è¨Šæ¯
                reply_message(reply_token, [TextMessage(text=full_text)])
                
    except Exception as e:
        logger.error(f"[LIST_FAILED] è™•ç†å¤±æ•—ä¸Šå‚³è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        reply_message(reply_token, [TextMessage(text="æŸ¥è©¢å¤±æ•—ä¸Šå‚³è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")])
    finally:
        conn.close()

@celery.task
def handle_show_complete_group_task(reply_token, user_id):
    logger = logging.getLogger('celery')
            
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # æŸ¥è©¢ä½¿ç”¨è€…ç¶å®šçš„æ‰€æœ‰ç¾¤çµ„
            logger.info("[SHOWCOMPLETEGROUP] Querying all groups for user_id=%s", user_id)
            cursor.execute('''
                SELECT gu.group_id, fm.folder_id, gi.name 
                FROM group_users gu 
                LEFT JOIN folder_map fm 

                    ON fm.source_id = gu.group_id 
                    AND fm.user_id = gu.user_id 
                LEFT JOIN group_info gi
                    ON gi.group_id = gu.group_id
                WHERE gu.user_id = %s
                ORDER BY gi.name, gu.group_id
                ''', (user_id,))
                

            groups = cursor.fetchall()
            
            if not groups:
                reply_text = "æ‚¨å°šæœªç¶å®šä»»ä½•ç¾¤çµ„ã€‚"
            else:
                all_groups_text = []
                for i, (group_id, folder_id, group_name) in enumerate(groups, 1):
                    group_text = f"{i}. {group_name or 'æœªå‘½åç¾¤çµ„'}\n"
                    group_text += f"ID: {group_id}\n"
                    if folder_id:
                        folder_url = f"https://drive.google.com/drive/folders/{folder_id}?authuser=0&openExternalBrowser=1"
                        group_text += f"è³‡æ–™å¤¾é€£çµ: {folder_url}"
                    else:
                        group_text += "å°šæœªå»ºç«‹å°æ‡‰çš„ Google Drive è³‡æ–™å¤¾"
                    all_groups_text.append(group_text)
                
                reply_text = "ä»¥ä¸‹æ˜¯å®Œæ•´çš„ç¾¤çµ„æ¸…å–®ï¼š\n\n" + '\n\n'.join(all_groups_text)

            logger.info("[SHOWCOMPLETEGROUP] æ‰¾åˆ° %d å€‹ç¾¤çµ„", len(groups))
            
        reply_message(reply_token, [TextMessage(text=reply_text)])
    except Exception as e:
        logger.error("[SHOWCOMPLETEGROUP] è™•ç†ç¾¤çµ„åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", str(e))
        reply_text = "å–å¾—ç¾¤çµ„åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        reply_message(reply_token, [TextMessage(text=reply_text)])
    finally:
        conn.close()
